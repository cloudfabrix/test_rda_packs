%% stream = no and limit = 0

%% import_source = "asset-discovery"

## @c:new-block
## --> @exec:get-input
## --> @dm:save name = "ondemand-inp-ui-data"
@c:new-block
    --> @dm:empty
    --> @dm:save name="temp-main_discovery_result"

--> @c:new-block
    --> @dm:empty
    --> #dm:query-persistent-stream *
            with-input name = "discovery" & limit = "0"
    --> @dm:save name = "temp-discovery"

--> @c:new-block
    --> @dm:empty
    --> #dm:query-persistent-stream *
            with-input name = "rda_system_organizations" & limit = "0"
    --> @dm:selectcolumns include= "projectId"
    --> @dm:rename-columns project_id = "projectId"
    --> @dm:eval key='"key"'
    --> @dm:save name = "temp-system-organization"

## Query Successfull devices after Access Verification
--> @c:new-block
    --> @dm:empty
    --> #dm:query-persistent-stream collection_status = 'Success'
            with-input name = "network_access_verification" & limit = "0"
    --> @dm:selectcolumns exclude= "limit|index|name"
    ## --> @dm:save name = "check-row"
    --> *exec:if-shape num_cols = 0
       --> @dm:eval ds_name = "'discovery'"
       --> @dm:eval discovery_time = "int(time_now_as_ms())"
       --> @dm:manipulate-string from="discovery_time,ds_name" and func="concat_columns" and to="ingestion_id"
       --> @dm:map from = 'ingestion_id' & to = 'ingestion_id' & func = 'md5'
       --> @dm:eval status = '"Collection Status for Devices is failed"'
       ## --> @dm:replace-data columns="status" and expr="Input dataframe does have Successfull collected devices" and replace="Data collection failed"
       ## --> @dm:eval pipline_exec_failure_reason = '"Collection Status for Devices is failed"'
       ## --> @dm:eval status =  '"Collection Status for Devices is failed : "+ pipline_exec_failure_reason'
       ## --> @dm:replace-data columns="status" and expr="Input dataframe to met failure criteria '{}'. Aborting" and replace="Data collection failed"
       --> @dm:eval key='"key"'
       --> @dm:eval source ="'Logs'"
       --> @dm:eval unique_id = "ingestion_id+'_'+status"
       --> @dm:eval discovery_end_time = "int(time_now_as_ms())"
       --> @dm:eval discovery_status = '"Failed"'
       --> @dm:selectcolumns include="project_id|status|unique_id|key|source|ingestion_id|discovery_end_time|discovery_time|discovery_status"
       --> @rn:write-stream name= "discovery_run_details"
       --> @dm:eval source ="'Counts'"
       --> @dm:to-type columns = "discovery_time" & type = "str"
       --> @dm:eval unique_id = "discovery_time+'_'+ingestion_id+'_'+source"
       --> @dm:to-type columns = "discovery_time" & type = "int"
       --> @rn:write-stream name= "discovery_run_details"
       --> @dm:selectcolumns exclude="project_id|status|unique_id|key|source|ingestion_id|discovery_end_time|discovery_time|discovery_status"
       --> @dm:save name = "check-row2"
       --> @dm:fail-if-shape column_count=0
    --> @exec:end-if
    --> *exec:if-shape num_cols > 0
       ## --> @dm:eval key='"key"' and discovery_scope = '"yes"'
       --> @dm:eval key='"key"'
       --> @dm:eval parts = "ip_address.split('.')[:3]"
       --> @dm:eval common_ip = "'.'.join(parts) + '.*'"
       --> @dm:enrich dict="temp-discovery" and src_key_cols="common_ip" and dict_key_cols="device_ip" and enrich_cols="discovery_scope" & enrich_cols_as = "discovery_scope1"
       --> @dm:selectcolumns exclude = "parts|device_ip"
       --> @dm:enrich dict="temp-discovery" and src_key_cols="ip_address" and dict_key_cols="device_ip" and enrich_cols="discovery_scope" & enrich_cols_as = "discovery_scope2"
       --> @dm:eval discovery_scope = "discovery_scope2 if discovery_scope2 else discovery_scope1"
       --> @dm:selectcolumns include="discovery_scope|key|ip_address|collection_timestamp"
       --> @dm:rename-columns device_ip  = "ip_address"
       --> @dm:selectcolumns exclude= "limit|index|name"
       --> @dm:save name = "temp-discovery"
       --> @dm:save name = "discovery"
    --> @exec:end-if

--> @c:flex-block
    --> @dm:empty
    --> @exec:define-function name = 'test-func'
       --> @exec:run-pipeline name="juniper_discovery_main_pipeline"
       --> @exec:run-pipeline name="cisco_discovery_main_pipeline"
       ## --> @exec:run-pipeline name="vyatta_discovery_main_pipeline"
       --> @exec:run-pipeline name="fortinet_discovery_main_pipeline"
       ## --> @exec:run-pipeline name="viptela_discovery_main_pipeline"
       --> @exec:run-pipeline name="discovery_main_pipeline"
    --> @exec:end-function

## ondemand execution
--> @c:new-block
    --> @exec:get-input
    --> @dm:save name = "ondemand-inp-ui-data"
    ## explode others and enrich the discovery_scope
    --> @dm:skip-block-if-shape row_count= 0
    --> @dm:selectcolumns include = "Others"
    ##--> @dm:eval Others = 'Others.replace("\'", "\"")'
    --> @dm:explode-json column="Others"
    --> @dm:save name = "temp-discovery-ondemand"
    --> #dm:query-persistent-stream collection_status = 'Success'
            with-input name = "network_access_verification" & limit = "0"
    --> @dm:eval key='"key"'
    --> @dm:eval parts = "ip_address.split('.')[:3]"
    --> @dm:eval common_ip = "'.'.join(parts) + '.*'"
    --> @dm:enrich dict="temp-discovery-ondemand" and src_key_cols="common_ip" and dict_key_cols="device_ip" and enrich_cols="discovery_scope" & enrich_cols_as = "discovery_scope1"
    --> @dm:selectcolumns exclude = "parts|device_ip"
    --> @dm:enrich dict="temp-discovery-ondemand" and src_key_cols="ip_address" and dict_key_cols="device_ip" and enrich_cols="discovery_scope" & enrich_cols_as = "discovery_scope2"
    --> @dm:eval discovery_scope = "discovery_scope2 if discovery_scope2 else discovery_scope1"
    --> @dm:selectcolumns include="discovery_scope|key|ip_address|collection_timestamp"
    --> @dm:rename-columns device_ip  = "ip_address"
    --> @dm:selectcolumns exclude= "limit|index|name"
    --> @dm:save name = "temp-discovery-ondemand"
    --> @dm:save name = "discovery"
    --> @dm:enrich dict	 = "temp-system-organization" and src_key_cols = "key" and dict_key_cols ="key" and enrich_cols ="project_id"
    ## --> @dm:save name = "temp-discovery"
    ## --> @dm:selectcolumns include="project_id"
    --> @dm:eval current_time ='int(time_now_as_ms())'
    --> @dm:eval ds_name="'discovery'"
    --> @dm:copy-columns from="current_time" and to="new_current_time"
    --> @dm:to-type columns="new_current_time,ds_name" and type="str"
    --> @dm:manipulate-string from="new_current_time,ds_name" and func="concat_columns" and to="ingestion_id"
    --> @dm:map from = 'ingestion_id' & to = 'ingestion_id' & func = 'md5'
    --> @dm:add-missing-columns columns="discovery_enabled" and value="yes"
    --> @dm:eval pipeline_name="'discovery_main_pipeline'"
    --> @dm:rename-columns project_id=project_id
    --> @dm:save name="temp-customer-details"
    --> @dm:add-missing-columns columns="credential_pattern"
    --> @dm:fixnull columns="credential_pattern"
    --> @dm:eval credential_pattern  = "'.*'"
    ## --> @dm:save name="main_discovery-ui"
    --> @exec:run-pipeline-by-row-multi-proc pipeline_col="pipeline_name" and save_output="yes"
    --> @dm:save name="temp-main_discovery_result"
    ## --> @dm:save name="main_discovery_result-ui"
    --> @dm:save name="temp-run_discovery-result"

## scheduled execution
--> @c:new-block
    --> @dm:recall name="temp-main_discovery_result"
    --> @dm:skip-block-if-shape row_count > 0
    --> @dm:recall name = "temp-discovery"
    --> @dm:enrich dict	 = "temp-system-organization" and src_key_cols = "key" and dict_key_cols ="key" and enrich_cols ="project_id"
    --> @dm:eval current_time ='int(time_now_as_ms())'
    --> @dm:rename-columns discovery_enabled = "discovery_scope"
    --> @dm:eval ds_name="'discovery'"
    --> @dm:copy-columns from="current_time" and to="new_current_time"
    --> @dm:to-type columns="new_current_time,ds_name" and type="str"
    --> @dm:manipulate-string from="new_current_time,ds_name" and func="concat_columns" and to="ingestion_id"
    --> @dm:map from = 'ingestion_id' & to = 'ingestion_id' & func = 'md5'
    ## --> @dm:add-missing-columns columns="discovery_enabled" and value="yes"
    --> @dm:eval pipeline_name="'discovery_main_pipeline'"
    --> @dm:save name="temp-customer-details"
    --> @dm:add-missing-columns columns="credential_pattern"
    --> @dm:fixnull columns="credential_pattern"
    --> @dm:eval credential_pattern  = "'.*'"
    --> @dm:selectcolumns exclude= "device_ip|count_|_RDA_Id|timestamp|key"
    --> @dm:dedup columns = "ds_name"
    ## --> @dm:save name="main_discovery"
    --> @exec:run-pipeline-by-row-multi-proc pipeline_col="pipeline_name" and save_output="yes"
    ## --> @dm:save name="main_discovery_result"
    --> @dm:save name="temp-run_discovery-result"

--> @c:new-block
    --> @dm:recall name="temp-run_discovery-result"
    --> *dm:filter pipline_exec_failure_reason is not null
    --> @dm:skip-block-if-shape row_count= 0
    --> @dm:eval status = '"Discovery failed due to error: "+pipline_exec_failure_reason '
    --> @dm:replace-data columns="status" and expr="Input dataframe to met failure criteria '{}'. Aborting" and replace="Data collection failed"
    --> @dm:eval key='"key"'
    --> @dm:eval source ="'Logs'"
    --> @dm:eval unique_id = "ingestion_id+'_'+status"
    --> @dm:selectcolumns include="project_id|status|unique_id|key|source|ingestion_id"
    --> @rn:write-stream name= "discovery_run_details"

--> @c:new-block
    --> @dm:recall name="temp-run_discovery-result"
    --> *dm:filter pipline_exec_failure_reason is not null
    --> @dm:skip-block-if-shape row_count=0
    --> @dm:eval source  ="'Counts'"
    ## --> @dm:add-missing-columns columns="discovery_end_time"
    --> @dm:eval discovery_end_time = "int(time_now_as_ms())"
    --> @dm:eval discovery_status ="'Failed'"
    --> @dm:copy-columns from="current_time" and to="discovery_time"
    --> @dm:copy-columns from="current_time" and to="new_current_time"
    --> @dm:to-type columns="new_current_time" and type="str"
    --> @dm:eval unique_id = "new_current_time+'_'+ingestion_id+'_'+source"
    --> @dm:selectcolumns include="source|unique_id|ingestion_id|discovery_time|discovery_end_time|discovery_status"
    --> @rn:write-stream name= "discovery_run_details"

